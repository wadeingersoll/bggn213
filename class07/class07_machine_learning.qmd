---
title: "Class 7: Machine Learning 1"
author: "Wade Ingersoll (PID: 69038080)"
format: pdf
---

Today we will begin our exploration of some "classical" machine learning approaches. We will start with clustering.

Let's first make up some data to cluster where we know what the answer should be.

```{r}
rnorm(10)
```

```{r}
hist( rnorm(1000) )
```

```{r}
x <- c( rnorm(30, mean=-3), rnorm(30, mean=3) )
y <- rev(x)

x <- cbind(x, y)
head(x)
```

A look at x with `plot()`

```{r}
plot(x)
```

Then main function in "base" R for K-means clustering is called `kmeans()`

```{r}
k <- kmeans(x, centers = 2)
k
```

> Q. How big are the clusters (i.e. their size)?

```{r}
k$size
```

> Q. What clusters do my data points reside in?

```{r}
k$cluster
```

> Q. Make a plot of our data colored by cluster assignment - i.e. Make a result figure...

```{r}

plot(x, col=k$cluster)
points(k$centers, col="blue", pch=15)
```

> Q. Cluster with k-means into 4 clusters and plot the results as above.

```{r}
x <- c( rnorm(30, mean=-3), rnorm(30, mean=3) )
y <- rev(x)
x <- cbind(x, y)

k <- kmeans(x, centers = 4)

plot(x, col=k$cluster)
points(k$centers, col="blue", pch=15)
```

> Q. Run kmeans with center (i.e. values of k) equal 1 to 6

```{r}
k1 <- kmeans(x, centers=1)$tot.withinss
k2 <- kmeans(x, centers=2)$tot.withinss
k3 <- kmeans(x, centers=3)$tot.withinss
k4 <- kmeans(x, centers=4)$tot.withinss
k5 <- kmeans(x, centers=5)$tot.withinss
k6 <- kmeans(x, centers=6)$tot.withinss

answer <- c(k1, k2, k3, k4, k5, k6)
```

Or use a for loop

```{r}
answer <- NULL
for (i in 1:6) {
  answer <- c(answer, kmeans(x, centers=i)$tot.withinss)
}
answer
```

Make a "scree-plot"

```{r}
plot(answer, typ="b")
```


## Hierarchical Clustering

The main function in "base" R for this is called `hclust()`

```{r}
d <- dist(x)
hc <- hclust(d)
hc
```

```{r}
plot(hc)
abline(h=7, col="red")
```

To obtain clusters from our `hclust()` result object **hc** we "cut" the tree to yield different sub branches. For this we use the `cutree()` function

```{r}
cutree(hc, k=7)
```

```{r}
library(pheatmap)

pheatmap(x)
```

## Principal Component Analysis (PCA)

```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url)
```

> Q1: How many rows and columns are in your new data frame named x? What R functions could you use to answer this questions?

> A: Using the code below, I found there are 17 rows and 5 columns

```{r}
# Complete the following code to find out how many rows and columns are in x?
dim(x)
```

## Preview the first 6 rows

```{r}
head(x)
```

```{r}
# Note how the minus indexing works
rownames(x) <- x[,1]
x <- x[,-1]
head(x)
```

> Q2: Which approach to solving the ‘row-names problem’ mentioned above do you prefer and why? Is one approach more robust than another under certain circumstances?

> A: The code below can solve this problem. This version works better if you plan to run the code multiple times.

```{r}
x <- read.csv(url, row.names=1)
head(x)
```

## Spotting major differences and trends

```{r}
rainbow(5)
```

## Using base R
```{r}
barplot(as.matrix(x), beside=T, col=rainbow(nrow(x)))
```

> Q3: Changing what optional argument in the above barplot() function results in the following plot?

> A: Changing `beside` to `F`

```{r}
barplot(as.matrix(x), beside=F, col=rainbow(nrow(x)))
```
# Convert data to long format for ggplot with `pivot_longer()`

```{r}
library(tidyr)

x_long <- x |> 
          tibble::rownames_to_column("Food") |> 
          pivot_longer(cols = -Food, 
                       names_to = "Country", 
                       values_to = "Consumption")

dim(x_long)
```

> Q4: Changing what optional argument in the above ggplot() code results in a stacked barplot figure?

> A: Adding an argument `position = "stack"` within geom_col()

```{r}
library(ggplot2)

ggplot(x_long) +
  aes(x = Country, y = Consumption, fill = Food) +
  geom_col(position = "stack") +
  theme_bw()
```


> Q5: We can use the pairs() function to generate all pairwise plots for our countries. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?

> A: Each point is a food and when they lie on the diagonal, it means the two countries eat it at the same rate

```{r}
pairs(x, col=rainbow(nrow(x)), pch=16)
```

```{r}
library(pheatmap)

pheatmap( as.matrix(x) )
```

>Q6. Based on the pairs and heatmap figures, which countries cluster together and what does this suggest about their food consumption patterns? Can you easily tell what the main differences between N. Ireland and the other countries of the UK in terms of this data-set?

> A: It looks like Wales and England are quite similar in their consumption of these foods. It is still quite difficult to tell what is going on in the dataset.

## PCA to the rescue

The main function in "base" R for PCA is called `prcomp()`.

As we want to do PCA on the food data for the different countries, we will want the foods in the columns.

```{r}
pca <- prcomp( t(x) )
summary(pca)
pca$x
```
Our result object is called `pca` and it has a `$x` component that we will look at first

> Q7. Complete the code below to generate a plot of PC1 vs PC2. The second line adds text labels over the data points.

```{r}
library(ggplot2)

# Create a data frame for plotting
df <- as.data.frame(pca$x)
df$Country <- rownames(df)

# Plot PC1 vs PC2 with ggplot
ggplot(pca$x) +
  aes(x = PC1, y = PC2, label = rownames(pca$x)) +
  geom_point(size = 3) +
  geom_text(vjust = -0.5) +
  xlim(-270, 500) +
  xlab("PC1") +
  ylab("PC2") +
  theme_bw()
```

> Q8. Customize your plot so that the colors of the country names match the colors in our UK and Ireland map and table at start of this document.

```{r}
library(ggplot2)

cols <- c("orange", "red", "blue", "darkgreen")

# Plot PC1 vs PC2 with ggplot
ggplot(pca$x) +
  aes(x = PC1, y = PC2, label = rownames(pca$x)) +
  geom_point(size = 3) +
  geom_text(vjust = -0.5, col=cols) +
  xlim(-270, 500) +
  xlab("PC1") +
  ylab("PC2") +
  theme_bw()
```

Another major result out of the PCA is the so-called "variable loadings" or `$rotation` that tells us how the original variables (foods) contribute to the PCs (i.e. our new axis).

```{r}
ggplot(pca$rotation) +
  aes(PC1, rownames(pca$rotation)) +
  geom_col()
```
## Lets focus on PC1 as it accounts for > 90% of variance

```{r}
 ggplot(pca$rotation) +
  aes(x = PC1, 
      y = reorder(rownames(pca$rotation), PC1)) +
  geom_col(fill = "steelblue") +
  xlab("PC1 Loading Score") +
  ylab("") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 9))
```
> Q9: Generate a similar ‘loadings plot’ for PC2. What two food groups feature prominantely and what does PC2 maninly tell us about?

```{r}
 ggplot(pca$rotation) +
  aes(x = PC2, 
      y = reorder(rownames(pca$rotation), PC2)) +
  geom_col(fill = "skyblue") +
  xlab("PC2 Loading Score") +
  ylab("") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 9))
```

## PCA of RNA-seq data

```{r}
url2 <- "https://tinyurl.com/expression-CSV"
rna.data <- read.csv(url2, row.names=1)
head(rna.data)
```

> Q10: How many genes and samples are in this data set? How many PCs do you think it will take to have a useful overview of this data set (see below)?

> A: Using `dim()`, there are 100 genes and 10 samples. I think it will take just 1 PC to have a useful overview of the data set.

```{r}
dim(rna.data)
```

```{r}
## Again we have to take the transpose of our data 
pca <- prcomp(t(rna.data), scale=TRUE)

# Create data frame for plotting
df <- as.data.frame(pca$x)
df$Sample <- rownames(df)

## Plot with ggplot
ggplot(df) +
  aes(x = PC1, y = PC2, label = Sample) +
  geom_point(size = 3) +
  geom_text(vjust = -0.5, size = 3) +
  xlab("PC1") +
  ylab("PC2") +
  theme_bw()
```

## Examine variation in original data

```{r}
summary(pca)
```

# A quick scree plot summary of this Proportion of Variance for each PC can be obtained using ggplot:

```{r}
# Calculate variance explained
pca.var <- pca$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100, 1)

# Create scree plot data
scree_df <- data.frame(
  PC = factor(paste0("PC", 1:10), levels = paste0("PC", 1:10)),
  Variance = pca.var[1:10]
)

ggplot(scree_df) +
  aes(x = PC, y = Variance) +
  geom_col(fill = "steelblue") +
  ggtitle("Quick scree plot") +
  xlab("Principal Component") +
  ylab("Variance") +
  theme_bw()
```
## Percent variance is often more informative to look at
```{r}
pca.var.per
```

# Create percent variance scree plot
```{r}
scree_pct_df <- data.frame(
  PC = factor(paste0("PC", 1:10), levels = paste0("PC", 1:10)),
  PercentVariation = pca.var.per[1:10]
)

ggplot(scree_pct_df) +
  aes(x = PC, y = PercentVariation) +
  geom_col(fill = "steelblue") +
  ggtitle("Scree Plot") +
  xlab("Principal Component") +
  ylab("Percent Variation") +
  theme_bw()
```

## Now lets make our main PCA plot a bit more attractive and useful…

```{r}
## A vector of colors for wt and ko samples
colvec <- colnames(rna.data)
colvec[grep("wt", colvec)] <- "red"
colvec[grep("ko", colvec)] <- "blue"

# Add condition to data frame
df$condition <- substr(df$Sample, 1, 2)
df$color <- colvec

ggplot(df) +
  aes(x = PC1, y = PC2, color = color, label = Sample) +
  geom_point(size = 3) +
  geom_text(vjust = -0.5, hjust = 0.5, show.legend = FALSE) +
  scale_color_identity() +
  xlab(paste0("PC1 (", pca.var.per[1], "%)")) +
  ylab(paste0("PC2 (", pca.var.per[2], "%)")) +
  theme_bw()
```

## Optional Gene Loadings

> For demonstration purposes let’s find the top 10 measurements (genes) that contribute most to pc1 in either direction (+ or -).

```{r}
loading_scores <- pca$rotation[,1]

## Find the top 10 measurements (genes) that contribute
## most to PC1 in either direction (+ or -)
gene_scores <- abs(loading_scores) 
gene_score_ranked <- sort(gene_scores, decreasing=TRUE)

## show the names of the top 10 genes
top_10_genes <- names(gene_score_ranked[1:10])
top_10_genes 
```

